# MULTIVAR

The multivar package in `contrib` is designed to allow you to use the 4dVarNet model with multiple variables as input and/or output.

## DATA LOADING

The data loading specifics are handled in `contrib.data_loading.data.py` with the 3 methods:
- `open_multivar_datasets` : This method uses the multivar dictionnary generated by your hydra configuration to call upon the following functions appropriately. It also generates a new dictionnary `multivar_information` that will be passed to other objects.
- `open_var_dataset` : This method will be called for each individual variable mentioned within your multivar dictionnary
- `merge_datasets` : This method merges your variable datasets iteratively.

### DATA AND VARIABLE OPTIONS:

For each variable added to the multivar configuration, these options must be specified:
- `var_path` : The path to search for the dataset to load.
- `mask_path` : Use this option only in the case where your **input** variable has to be masked to simulate observations. Gives the path in which to find the numpy masks in a **.pickle** form.
- `var_name` : This name has to be the exact variable name to select your variable in the dataset specified in `var_path`.
- `input_arch`:
    - **full_input** : This variable will be used for input/output, it contains observations to be used within the model structure.
    - **prior_input** : This variable will be used solely as input to inform the prior model.
- `output_arch` :
    - **full_output** : This variable will be reconstructed by the model.
    - **no_output** : This variable will not be reconstructed by the model.
- `broadcast_time` : Set this to `True` if your variable contains only one day of constant data, and you wish it to be broadcast along the time dimension.
- `aug` : Set this to `True` if you wish to use the augmentation method.
    > The augmentation will be performed by applying the mask of this variable on the next variable in your configuration. Alternatively, if `mask_path` is set, the augmentation will be applied with the masks.
- `fill_nan` : Fills the nans of your dataset with a specific value (takes place before normalisation).


## BATCH SELECTOR

The `BatchSelector` Singleton class, defined in `contrib.multivar.multivar_utils.py` is designed to make use of the generated multivar dataset. Indeed, after going through the data-loading, the dataloaders will create batches containing your variables stacked together along a new dimension.

To make use of these batches inside of the `contrib.multivar.multivar_models.py`, the `BatchSelector` class is used. Once it is initialized, it is setup using the `multivar_setup` method, which requires the `multivar_information` dict created by the `open_multivar_datasets` method.
> In a model, calling `self.multivar_selector.multivar_full_output(batch)` will yield only the target dimensions of your batch.


## MULTIVAR MODELS

In `contrib.multivar.multivar_models.py` you can find the models tailored to multivar use.

Most changes relate to dimension manipulation, like handling normalisation, using batch_selector to make use of batches, etc.

The method used to output results `on_test_epoch_end` is also modified to created leadtimes of specific dimensions iteratively, named **test_data_14_dim0.nc**, then **test_data_14_dim1.nc** if you have 2 output dimensions for instance.

### To Implement

In `Multivar4dVarNet.multivar_step` and `.step`, there should be a loop over multiple dimensions to compute the losses over different variables and log them separately.

The call to `self.norm_stats[1]**2` in the logged mse is a placeholder returning 1 and should be replaced by `self.output_norm_stats[var_out][1]**2` when the previous step to implement is done with.


## OUTPUTS

You will find `ose_pipeline` configuration files in the `contrib` folders, specifically for multivar implementations.

These configurations contain most notably the `multivar: True` and `metrics_dim: 0` keywords in the `options.overrides` sections of the configuration files.

___
___
Pierre Hasl√©e