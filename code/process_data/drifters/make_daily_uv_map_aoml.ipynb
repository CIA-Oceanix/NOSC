{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import reference grid\n",
      "Reference grid imported\n",
      "2010-01-01 00:00:00\n",
      "2010\n",
      "Saving...\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.append(\"../../tools\")\n",
    "from plot_tools import plot_uv_map,plot_map_zoom\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy\n",
    "import netCDF4\n",
    "import datetime\n",
    "import os\n",
    "from typing import Optional, Tuple\n",
    "from scipy import stats\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "\n",
    "lon_bins = np.linspace(-180.125, 179.916672 + 0.125, 1441)\n",
    "lat_bins = np.linspace(-80.125, 90.125, 681)\n",
    "\n",
    "print(\"Import reference grid\" )\n",
    "# Import reference grid \n",
    "map_4th = \"/Odyssey/private/t22picar/data/glorys_15m/glorys_multivar_15m_2010-2018.nc\"\n",
    "map_4th = xr.open_dataset(map_4th).sel(time=\"2010-01-01\")\n",
    "lat = map_4th.lat.values\n",
    "lon = map_4th.lon.values\n",
    "#lon = (lon_bins[1:] + lon_bins[:-1]) / 2\n",
    "#lat = (lat_bins[1:] + lat_bins[:-1]) / 2\n",
    "print(\"Reference grid imported\" )\n",
    "\n",
    "\n",
    "start_date = datetime(2010, 1, 1)\n",
    "end_date = datetime(2010, 1, 2)\n",
    "\n",
    "current_date = start_date\n",
    "time_index = 0\n",
    "year = 0\n",
    "\n",
    "u_drifter_list =[]\n",
    "v_drifter_list =[]\n",
    "\n",
    "print(current_date)\n",
    "\n",
    "while current_date < end_date:\n",
    "        \n",
    "        check_year = current_date.year\n",
    "        if check_year != year:\n",
    "                print(check_year)\n",
    "                year = check_year\n",
    "                filenames_drifters = sorted(glob(f'/Odyssey/public/drifters/aoml/drifter_*_{year}.nc'))\n",
    "                ds_drifter = xr.open_mfdataset(filenames_drifters, combine='nested', concat_dim='date')\n",
    "                ds_drifter = ds_drifter.sel(date=ds_drifter[\"date.year\"] == year)\n",
    "                ds_drifter = ds_drifter.compute()\n",
    "                ds_drifter = ds_drifter.where(ds_drifter['ums'] < 1000, drop=True)\n",
    "                ds_drifter = ds_drifter.where(ds_drifter['vms'] < 1000, drop=True) \n",
    "\n",
    "        # Make daily bin map with u, v mean\n",
    "        day_ds_drifter = ds_drifter.sel(date = current_date.strftime(\"%Y-%m-%d\"))\n",
    "        if day_ds_drifter.ums.values.shape[0]==0:\n",
    "                u_drifter = np.empty((lon.shape[0],lat.shape[0]))\n",
    "                u_drifter[:] = np.nan\n",
    "                v_drifter = np.empty((lon.shape[0],lat.shape[0]))\n",
    "                v_drifter[:] = np.nan\n",
    "        else :\n",
    "            u_drifter,x_edge,y_edge,binnumber = stats.binned_statistic_2d(day_ds_drifter.lon.values, day_ds_drifter.lat.values, day_ds_drifter.ums.values, 'mean', bins=[lon_bins, lat_bins])\n",
    "            v_drifter,x_edge,y_edge,binnumber = stats.binned_statistic_2d(day_ds_drifter.lon.values, day_ds_drifter.lat.values, day_ds_drifter.vms.values, 'mean', bins=[lon_bins, lat_bins])\n",
    "\n",
    "        # Créer un DataArray pour \"u\"\n",
    "        u_drifter_xr = xr.DataArray(\n",
    "        u_drifter.T,\n",
    "        dims=(\"lat\", \"lon\"),\n",
    "        coords={\n",
    "\n",
    "                \"lat\": lat,\n",
    "                \"lon\": lon,\n",
    "        },\n",
    "        name=\"u_drifter\"\n",
    "        ).expand_dims(time=[current_date])\n",
    "\n",
    "        # Créer un DataArray pour \"u\"\n",
    "        v_drifter_xr = xr.DataArray(\n",
    "        v_drifter.T,\n",
    "        dims=(\"lat\", \"lon\"),\n",
    "        coords={\n",
    "\n",
    "                \"lat\": lat,\n",
    "                \"lon\": lon,\n",
    "        },\n",
    "        name=\"v_drifter\"\n",
    "        ).expand_dims(time=[current_date])\n",
    "\n",
    "        u_drifter_list.append(u_drifter_xr)\n",
    "        v_drifter_list.append(v_drifter_xr)\n",
    "\n",
    "        current_date += timedelta(days=1)  # Ajoute 1 an (approximation)\n",
    "        time_index += 1\n",
    "\n",
    "\n",
    "# Concaténer tous les DataArrays le long de la dimension \"time\"\n",
    "u_drifter = xr.concat(u_drifter_list, dim=\"time\")\n",
    "v_drifter = xr.concat(v_drifter_list, dim=\"time\")\n",
    "\n",
    "# Créer le Dataset final\n",
    "ds = xr.Dataset({\"u_drifter\": u_drifter, \"v_drifter\": v_drifter})\n",
    "\n",
    "# Get the list of variable names\n",
    "variable_names = list(ds.variables.keys())\n",
    "variable_names.remove(\"time\")\n",
    "\n",
    "for var in variable_names:\n",
    "    ds[var] = ds[var].astype(np.float32)\n",
    "\n",
    "print(\"Saving...\")\n",
    "save_file=f\"/Odyssey/private/t22picar/data/drifters/daily_uv/drifters_uv_15m_aoml_4th.nc\"\n",
    "\n",
    "# Sauvegarder le DataArray en fichier NetCDF\n",
    "#ds.to_netcdf(save_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4dvarnet-daniel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
