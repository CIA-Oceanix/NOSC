{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "from utils_data import interpolation_glorys_raw_data,interpolation_era5_raw_data\n",
    "import xarray as xr\n",
    "# Define a reference grid :\n",
    "\n",
    "size_grid = \"8th\"\n",
    "coef = 2\n",
    "lon_ref = np.linspace(-180,180,1441*coef)[:-1]\n",
    "lat_ref = np.linspace(-90,90,721*coef)[:-1]\n",
    "\n",
    "\n",
    "# Define depth\n",
    "depth=15\n",
    "\n",
    "# Define a period of test : \n",
    "year = 2019\n",
    "\n",
    "# Create a directory\n",
    "\n",
    "folder_data = f\"/Odyssey/private/t22picar/data/train_glorys_{depth}_{size_grid}/\"\n",
    "if not os.path.exists(folder_data):\n",
    "    os.makedirs(folder_data)\n",
    "    print(f\"Le dossier '{folder_data}' a été créé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation of testing data + add a correction\n",
    "# SSH \n",
    "# Add offset due to different mdt\n",
    "time_end = \"2019-01-10\"\n",
    "time_start = \"2019-01-01\"\n",
    "\n",
    "def interpolation_ssh_raw_data(year,depth,folder_data): \n",
    "\n",
    "    folder_ssh = \"/Odyssey/private/t22picar/data/ssh_L4/\"\n",
    "    file_obs = \"SSH_L4_CMEMS_2019.nc\" # Actually not glorys \n",
    "\n",
    "    maps = xr.open_dataset(folder_ssh+file_obs).sel(time=slice(time_start,time_end))\n",
    "    maps = maps.rename({\"latitude\": \"lat\"})\n",
    "    maps = maps.rename({\"longitude\": \"lon\"})\n",
    "    maps = maps.rename({\"adt\": \"zos\"})\n",
    "\n",
    "    # Get the list of variable names\n",
    "    variable_names = list(maps.variables.keys())\n",
    "    variable_names.remove(\"time\")\n",
    "\n",
    "    for var in variable_names:\n",
    "        maps[var] = maps[var].astype(np.float32)\n",
    "\n",
    "    folder_glorys = f\"/Odyssey/private/t22picar/data/glorys_{depth}m/\"\n",
    "    file_glorys = f\"glorys_multivar_{depth}m_2019.nc\"\n",
    "    maps_glo = xr.open_dataset(folder_glorys+file_glorys).sel(time=slice(time_start,time_end))\n",
    "\n",
    "    mean_glorys_ssh = np.nanmean(maps_glo.zos.values)\n",
    "    mean_sat_ssh = np.nanmean(maps.zos.values)\n",
    "    offset = mean_glorys_ssh-mean_sat_ssh\n",
    "\n",
    "    maps.zos.values = maps.zos.values + offset\n",
    "\n",
    "    print(\"Interpolation cmems ssh ... \")\n",
    "    maps = regrid_da(maps)\n",
    "    print(\"Interpolation done\")\n",
    "\n",
    "    # save data \n",
    "    print(\"Saving...\")\n",
    "    save_file=folder_data+f\"cmems_ssh_{year}.nc\"\n",
    "    print(save_file)\n",
    "    # Sauvegarder le DataArray en fichier NetCDF\n",
    "    maps.to_netcdf(save_file)\n",
    "    print(\"Saving done\")\n",
    "\n",
    "# SST \n",
    "\n",
    "def interpolation_sst_raw_data(year,depth,folder_data):\n",
    "    folder_sst = \"/Odyssey/private/t22picar/data/sst_L4/\"\n",
    "    file_sst = \"SST_L4_OSTIA_2019.nc\"\n",
    "\n",
    "    maps = xr.open_dataset(folder_sst+file_sst).sel(time=slice(time_start,time_end))\n",
    "    maps = maps.rename({\"latitude\": \"lat\"})\n",
    "    maps = maps.rename({\"longitude\": \"lon\"})\n",
    "    maps = maps.rename({\"analysed_sst\": \"thetao\"})\n",
    "\n",
    "    # Get the list of variable names\n",
    "    variable_names = list(maps.variables.keys())\n",
    "    variable_names.remove(\"time\")\n",
    "\n",
    "    for var in variable_names:\n",
    "        maps[var] = maps[var].astype(np.float32)\n",
    "\n",
    "\n",
    "    print(\"Interpolation ostia ssh ... \")\n",
    "    # Interpolation new grid\n",
    "    maps = regrid_da(maps)\n",
    "    maps.thetao.values = maps.thetao.values - 273.15\n",
    "    print(\"Interpolation done\")\n",
    "\n",
    "\n",
    "    # save data \n",
    "    print(\"Saving...\")\n",
    "    save_file=folder_data+f\"ostia_sst_{year}\"+\".nc\"\n",
    "    print(save_file)\n",
    "    # Sauvegarder le DataArray en fichier NetCDF\n",
    "    maps.to_netcdf(save_file)\n",
    "    print(\"Saving done\")\n",
    "\n",
    "def interpolation_era5_raw_data_test(folder_data):\n",
    "\n",
    "    print(\"open data\")\n",
    "    folder_era5 = \"/Odyssey/private/t22picar/data/era5/\"\n",
    "    file_era5 = f\"era5_2019.grib\" # Actually not glorys \n",
    "    map_era5 = xr.open_dataset(folder_era5+file_era5, engine=\"cfgrib\").sel(time=slice(time_start,time_end))\n",
    "    map_era5['longitude'] = xr.where(map_era5['longitude'] > 180, map_era5['longitude'] - 360, map_era5['longitude'])\n",
    "    map_era5 = map_era5.rename({\"latitude\": \"lat\"})\n",
    "    map_era5 = map_era5.rename({\"longitude\": \"lon\"})\n",
    "\n",
    "    # Daily mean wind\n",
    "    print(\"computing daily mean era5 ...\")\n",
    "    map_era5 = map_era5.resample(valid_time='1D').mean()\n",
    "    print(\"computation daily mean done\")\n",
    "    # Interpolation new grid\n",
    "    print(\"Interpolating era5 ...\")\n",
    "    map_era5 = regrid_da(map_era5)\n",
    "    print(\"interpolation done\")\n",
    "    #Split into two files\n",
    "    map_era5 = map_era5.drop(\"number\").drop(\"step\").drop(\"surface\").rename({\"valid_time\": \"time\"})\n",
    "\n",
    "    # Get the list of variable names\n",
    "    variable_names = list(map_era5.variables.keys())\n",
    "    variable_names.remove(\"time\")\n",
    "\n",
    "    for var in variable_names:\n",
    "        map_era5[var] = map_era5[var].astype(np.float32)\n",
    "    # save data\n",
    "    print(\"Saving file ...\")\n",
    "    save_file=f\"era5_2019.nc\"\n",
    "\n",
    "    # Sauvegarder le DataArray en fichier NetCDF\n",
    "    map_era5.to_netcdf(folder_data+save_file)\n",
    "    print(\"Saving done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open data\n"
     ]
    }
   ],
   "source": [
    "# SSH \n",
    "#interpolation_ssh_raw_data(year,depth,folder_data)\n",
    "\n",
    "# SST \n",
    "\n",
    "#interpolation_sst_raw_data(year,depth,folder_data)\n",
    "\n",
    "#ERA? \n",
    "interpolation_era5_raw_data_test(folder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4dvarnet-daniel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
